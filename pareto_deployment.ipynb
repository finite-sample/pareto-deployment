{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Load and preprocess Adult data\n",
        "data = fetch_openml(\"adult\", version=2, as_frame=True)\n",
        "df = data.frame.dropna()\n",
        "X = pd.get_dummies(df.drop(\"class\", axis=1))\n",
        "y = (df[\"class\"] == \">50K\").astype(int)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y.values, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2. Train Model A (Logistic Regression) and B (MLP)\n",
        "model_A = LogisticRegression(max_iter=500, random_state=0)\n",
        "model_B = MLPClassifier(hidden_layer_sizes=(64,32), max_iter=40, random_state=42)\n",
        "\n",
        "model_A.fit(X_train, y_train)\n",
        "model_B.fit(X_train, y_train)\n",
        "\n",
        "A_pred = model_A.predict(X_test)\n",
        "B_pred = model_B.predict(X_test)\n",
        "\n",
        "# 3. Mark winner (A wins=0, B wins=1; break ties in favor of A)\n",
        "def winner(a, b, y):\n",
        "    if a == y and b != y:\n",
        "        return 0\n",
        "    elif b == y and a != y:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0  # Prefer A in ties\n",
        "\n",
        "winner_labels = np.array([winner(a, b, y0) for a, b, y0 in zip(A_pred, B_pred, y_test)])\n",
        "\n",
        "# 4. kNN Router (on test set; in production use, would train on deployment/validation set)\n",
        "knn_router = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_router.fit(X_test, winner_labels)  # Use X_test for simplicity (demonstration)\n",
        "\n",
        "# 5. Meta-classifier Router\n",
        "meta_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "meta_clf.fit(X_test, winner_labels)\n",
        "\n",
        "# 6. Routing predictions\n",
        "def deployed_pred(strategy, X):\n",
        "    if strategy == 'A':\n",
        "        return A_pred\n",
        "    elif strategy == 'B':\n",
        "        return B_pred\n",
        "    elif strategy == 'knn':\n",
        "        which_model = knn_router.predict(X)\n",
        "        return np.where(which_model == 0, A_pred, B_pred)\n",
        "    elif strategy == 'meta':\n",
        "        which_model = meta_clf.predict(X)\n",
        "        return np.where(which_model == 0, A_pred, B_pred)\n",
        "\n",
        "strategies = ['A', 'B', 'knn', 'meta']\n",
        "results = {}\n",
        "for strat in strategies:\n",
        "    preds = deployed_pred(strat, X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    # Regressions: A was correct, now wrong\n",
        "    regressions = ((A_pred == y_test) & (preds != y_test)).sum()\n",
        "    results[strat] = {'accuracy': acc, 'regressions': regressions}\n",
        "    print(f\"{strat:5s}  Accuracy: {acc:.4f}  Regressions vs. A: {regressions}\")\n",
        "\n",
        "# Optional: Show detailed reports\n",
        "for strat in strategies:\n",
        "    preds = deployed_pred(strat, X_test)\n",
        "    print(f\"\\n{strat.upper()} Classification report:\")\n",
        "    print(classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwGVyXUd3v9L",
        "outputId": "d15dce28-9e9b-428d-9fc1-dbc129343f67"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A      Accuracy: 0.8459  Regressions vs. A: 0\n",
            "B      Accuracy: 0.8396  Regressions vs. A: 368\n",
            "knn    Accuracy: 0.8501  Regressions vs. A: 15\n",
            "meta   Accuracy: 0.8802  Regressions vs. A: 0\n",
            "\n",
            "A Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.90      6803\n",
            "           1       0.73      0.60      0.66      2242\n",
            "\n",
            "    accuracy                           0.85      9045\n",
            "   macro avg       0.80      0.76      0.78      9045\n",
            "weighted avg       0.84      0.85      0.84      9045\n",
            "\n",
            "\n",
            "B Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.90      6803\n",
            "           1       0.71      0.60      0.65      2242\n",
            "\n",
            "    accuracy                           0.84      9045\n",
            "   macro avg       0.79      0.76      0.77      9045\n",
            "weighted avg       0.83      0.84      0.83      9045\n",
            "\n",
            "\n",
            "KNN Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.90      6803\n",
            "           1       0.74      0.61      0.67      2242\n",
            "\n",
            "    accuracy                           0.85      9045\n",
            "   macro avg       0.81      0.77      0.79      9045\n",
            "weighted avg       0.84      0.85      0.85      9045\n",
            "\n",
            "\n",
            "META Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92      6803\n",
            "           1       0.81      0.67      0.74      2242\n",
            "\n",
            "    accuracy                           0.88      9045\n",
            "   macro avg       0.85      0.81      0.83      9045\n",
            "weighted avg       0.88      0.88      0.88      9045\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BDxiiW2vnJry"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}